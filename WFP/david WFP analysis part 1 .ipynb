{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/preprocessing-text-data-using-python-576206753c28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Importing Libraries along with our Data\n",
    "2. Expanding Contractions\n",
    "3. Language Detection\n",
    "4. Tokenization\n",
    "5. Converting all Characters to Lowercase\n",
    "6. Removing Punctuations\n",
    "7. Removing Stopwords\n",
    "8. Parts of Speech Tagging\n",
    "9. Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import fasttext\n",
    "import spacy\n",
    "import contractions\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk import word_tokenize, pos_tag\n",
    "plt.xticks(rotation=70)\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "%matplotlib inline\n",
    "import importlib\n",
    "#import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('C:/Users/jeanl/Desktop/trial.csv',index_col=False)\n",
    "df = pd.read_pickle(\"C:/Users/mwamb/OneDrive/Desktop/tenthdimensionanalytics/WFP/wfpdata\")\n",
    "\n",
    "#\"C:/Users/David/Desktop/tenthdimensionanalytics/WFP/wfpdata\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    FOOD SECURITY \\n AND NUTRITION \\nIN THE WORLD\\nTHE STATE OF \\nSAFEGUARDING AGAINST \\nECONOMIC SL...\n",
      "Name: words, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df['words'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Pre-Processing\n",
    "### Expanding Contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>words</th>\n",
       "      <th>no_contract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>WFP</td>\n",
       "      <td>FOOD SECURITY \\n AND NUTRITION \\nIN THE WORLD\\nTHE STATE OF \\nSAFEGUARDING AGAINST \\nECONOMIC SL...</td>\n",
       "      <td>[FOOD, SECURITY, AND, NUTRITION, IN, THE, WORLD, THE, STATE, OF, SAFEGUARDING, AGAINST, ECONOMIC...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cluster  \\\n",
       "0     WFP   \n",
       "\n",
       "                                                                                                 words  \\\n",
       "0  FOOD SECURITY \\n AND NUTRITION \\nIN THE WORLD\\nTHE STATE OF \\nSAFEGUARDING AGAINST \\nECONOMIC SL...   \n",
       "\n",
       "                                                                                           no_contract  \n",
       "0  [FOOD, SECURITY, AND, NUTRITION, IN, THE, WORLD, THE, STATE, OF, SAFEGUARDING, AGAINST, ECONOMIC...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['no_contract'] = df['words'].apply(lambda x: [contractions.fix(word) for word in x.split()])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>words</th>\n",
       "      <th>no_contract</th>\n",
       "      <th>words_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>WFP</td>\n",
       "      <td>FOOD SECURITY \\n AND NUTRITION \\nIN THE WORLD\\nTHE STATE OF \\nSAFEGUARDING AGAINST \\nECONOMIC SL...</td>\n",
       "      <td>[FOOD, SECURITY, AND, NUTRITION, IN, THE, WORLD, THE, STATE, OF, SAFEGUARDING, AGAINST, ECONOMIC...</td>\n",
       "      <td>FOOD SECURITY AND NUTRITION IN THE WORLD THE STATE OF SAFEGUARDING AGAINST ECONOMIC SLOWDOWNS AN...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cluster  \\\n",
       "0     WFP   \n",
       "\n",
       "                                                                                                 words  \\\n",
       "0  FOOD SECURITY \\n AND NUTRITION \\nIN THE WORLD\\nTHE STATE OF \\nSAFEGUARDING AGAINST \\nECONOMIC SL...   \n",
       "\n",
       "                                                                                           no_contract  \\\n",
       "0  [FOOD, SECURITY, AND, NUTRITION, IN, THE, WORLD, THE, STATE, OF, SAFEGUARDING, AGAINST, ECONOMIC...   \n",
       "\n",
       "                                                                                             words_str  \n",
       "0  FOOD SECURITY AND NUTRITION IN THE WORLD THE STATE OF SAFEGUARDING AGAINST ECONOMIC SLOWDOWNS AN...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['words_str'] = [' '.join(map(str, l)) for l in df['no_contract']]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## English Language Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mwamb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>words</th>\n",
       "      <th>no_contract</th>\n",
       "      <th>words_str</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>WFP</td>\n",
       "      <td>FOOD SECURITY \\n AND NUTRITION \\nIN THE WORLD\\nTHE STATE OF \\nSAFEGUARDING AGAINST \\nECONOMIC SL...</td>\n",
       "      <td>[FOOD, SECURITY, AND, NUTRITION, IN, THE, WORLD, THE, STATE, OF, SAFEGUARDING, AGAINST, ECONOMIC...</td>\n",
       "      <td>FOOD SECURITY AND NUTRITION IN THE WORLD THE STATE OF SAFEGUARDING AGAINST ECONOMIC SLOWDOWNS AN...</td>\n",
       "      <td>[FOOD, SECURITY, AND, NUTRITION, IN, THE, WORLD, THE, STATE, OF, SAFEGUARDING, AGAINST, ECONOMIC...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cluster  \\\n",
       "0     WFP   \n",
       "\n",
       "                                                                                                 words  \\\n",
       "0  FOOD SECURITY \\n AND NUTRITION \\nIN THE WORLD\\nTHE STATE OF \\nSAFEGUARDING AGAINST \\nECONOMIC SL...   \n",
       "\n",
       "                                                                                           no_contract  \\\n",
       "0  [FOOD, SECURITY, AND, NUTRITION, IN, THE, WORLD, THE, STATE, OF, SAFEGUARDING, AGAINST, ECONOMIC...   \n",
       "\n",
       "                                                                                             words_str  \\\n",
       "0  FOOD SECURITY AND NUTRITION IN THE WORLD THE STATE OF SAFEGUARDING AGAINST ECONOMIC SLOWDOWNS AN...   \n",
       "\n",
       "                                                                                             tokenized  \n",
       "0  [FOOD, SECURITY, AND, NUTRITION, IN, THE, WORLD, THE, STATE, OF, SAFEGUARDING, AGAINST, ECONOMIC...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokenized'] = df['words_str'].apply(word_tokenize)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting all Characters to Lowercase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>words</th>\n",
       "      <th>no_contract</th>\n",
       "      <th>words_str</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>lower</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>WFP</td>\n",
       "      <td>FOOD SECURITY \\n AND NUTRITION \\nIN THE WORLD\\nTHE STATE OF \\nSAFEGUARDING AGAINST \\nECONOMIC SL...</td>\n",
       "      <td>[FOOD, SECURITY, AND, NUTRITION, IN, THE, WORLD, THE, STATE, OF, SAFEGUARDING, AGAINST, ECONOMIC...</td>\n",
       "      <td>FOOD SECURITY AND NUTRITION IN THE WORLD THE STATE OF SAFEGUARDING AGAINST ECONOMIC SLOWDOWNS AN...</td>\n",
       "      <td>[FOOD, SECURITY, AND, NUTRITION, IN, THE, WORLD, THE, STATE, OF, SAFEGUARDING, AGAINST, ECONOMIC...</td>\n",
       "      <td>[food, security, and, nutrition, in, the, world, the, state, of, safeguarding, against, economic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cluster  \\\n",
       "0     WFP   \n",
       "\n",
       "                                                                                                 words  \\\n",
       "0  FOOD SECURITY \\n AND NUTRITION \\nIN THE WORLD\\nTHE STATE OF \\nSAFEGUARDING AGAINST \\nECONOMIC SL...   \n",
       "\n",
       "                                                                                           no_contract  \\\n",
       "0  [FOOD, SECURITY, AND, NUTRITION, IN, THE, WORLD, THE, STATE, OF, SAFEGUARDING, AGAINST, ECONOMIC...   \n",
       "\n",
       "                                                                                             words_str  \\\n",
       "0  FOOD SECURITY AND NUTRITION IN THE WORLD THE STATE OF SAFEGUARDING AGAINST ECONOMIC SLOWDOWNS AN...   \n",
       "\n",
       "                                                                                             tokenized  \\\n",
       "0  [FOOD, SECURITY, AND, NUTRITION, IN, THE, WORLD, THE, STATE, OF, SAFEGUARDING, AGAINST, ECONOMIC...   \n",
       "\n",
       "                                                                                                 lower  \n",
       "0  [food, security, and, nutrition, in, the, world, the, state, of, safeguarding, against, economic...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['lower'] = df['tokenized'].apply(lambda x: [word.lower() for word in x])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>words</th>\n",
       "      <th>no_contract</th>\n",
       "      <th>words_str</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>lower</th>\n",
       "      <th>no_punc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>WFP</td>\n",
       "      <td>FOOD SECURITY \\n AND NUTRITION \\nIN THE WORLD\\nTHE STATE OF \\nSAFEGUARDING AGAINST \\nECONOMIC SL...</td>\n",
       "      <td>[FOOD, SECURITY, AND, NUTRITION, IN, THE, WORLD, THE, STATE, OF, SAFEGUARDING, AGAINST, ECONOMIC...</td>\n",
       "      <td>FOOD SECURITY AND NUTRITION IN THE WORLD THE STATE OF SAFEGUARDING AGAINST ECONOMIC SLOWDOWNS AN...</td>\n",
       "      <td>[FOOD, SECURITY, AND, NUTRITION, IN, THE, WORLD, THE, STATE, OF, SAFEGUARDING, AGAINST, ECONOMIC...</td>\n",
       "      <td>[food, security, and, nutrition, in, the, world, the, state, of, safeguarding, against, economic...</td>\n",
       "      <td>[food, security, and, nutrition, in, the, world, the, state, of, safeguarding, against, economic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cluster  \\\n",
       "0     WFP   \n",
       "\n",
       "                                                                                                 words  \\\n",
       "0  FOOD SECURITY \\n AND NUTRITION \\nIN THE WORLD\\nTHE STATE OF \\nSAFEGUARDING AGAINST \\nECONOMIC SL...   \n",
       "\n",
       "                                                                                           no_contract  \\\n",
       "0  [FOOD, SECURITY, AND, NUTRITION, IN, THE, WORLD, THE, STATE, OF, SAFEGUARDING, AGAINST, ECONOMIC...   \n",
       "\n",
       "                                                                                             words_str  \\\n",
       "0  FOOD SECURITY AND NUTRITION IN THE WORLD THE STATE OF SAFEGUARDING AGAINST ECONOMIC SLOWDOWNS AN...   \n",
       "\n",
       "                                                                                             tokenized  \\\n",
       "0  [FOOD, SECURITY, AND, NUTRITION, IN, THE, WORLD, THE, STATE, OF, SAFEGUARDING, AGAINST, ECONOMIC...   \n",
       "\n",
       "                                                                                                 lower  \\\n",
       "0  [food, security, and, nutrition, in, the, world, the, state, of, safeguarding, against, economic...   \n",
       "\n",
       "                                                                                               no_punc  \n",
       "0  [food, security, and, nutrition, in, the, world, the, state, of, safeguarding, against, economic...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punc = string.punctuation\n",
    "df['no_punc'] = df['lower'].apply(lambda x: [word for word in x if word not in punc])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>words</th>\n",
       "      <th>no_contract</th>\n",
       "      <th>words_str</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>lower</th>\n",
       "      <th>no_punc</th>\n",
       "      <th>stopwords_removed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>WFP</td>\n",
       "      <td>FOOD SECURITY \\n AND NUTRITION \\nIN THE WORLD\\nTHE STATE OF \\nSAFEGUARDING AGAINST \\nECONOMIC SL...</td>\n",
       "      <td>[FOOD, SECURITY, AND, NUTRITION, IN, THE, WORLD, THE, STATE, OF, SAFEGUARDING, AGAINST, ECONOMIC...</td>\n",
       "      <td>FOOD SECURITY AND NUTRITION IN THE WORLD THE STATE OF SAFEGUARDING AGAINST ECONOMIC SLOWDOWNS AN...</td>\n",
       "      <td>[FOOD, SECURITY, AND, NUTRITION, IN, THE, WORLD, THE, STATE, OF, SAFEGUARDING, AGAINST, ECONOMIC...</td>\n",
       "      <td>[food, security, and, nutrition, in, the, world, the, state, of, safeguarding, against, economic...</td>\n",
       "      <td>[food, security, and, nutrition, in, the, world, the, state, of, safeguarding, against, economic...</td>\n",
       "      <td>[food, security, nutrition, world, state, safeguarding, economic, slowdowns, downturnsdemocratic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cluster  \\\n",
       "0     WFP   \n",
       "\n",
       "                                                                                                 words  \\\n",
       "0  FOOD SECURITY \\n AND NUTRITION \\nIN THE WORLD\\nTHE STATE OF \\nSAFEGUARDING AGAINST \\nECONOMIC SL...   \n",
       "\n",
       "                                                                                           no_contract  \\\n",
       "0  [FOOD, SECURITY, AND, NUTRITION, IN, THE, WORLD, THE, STATE, OF, SAFEGUARDING, AGAINST, ECONOMIC...   \n",
       "\n",
       "                                                                                             words_str  \\\n",
       "0  FOOD SECURITY AND NUTRITION IN THE WORLD THE STATE OF SAFEGUARDING AGAINST ECONOMIC SLOWDOWNS AN...   \n",
       "\n",
       "                                                                                             tokenized  \\\n",
       "0  [FOOD, SECURITY, AND, NUTRITION, IN, THE, WORLD, THE, STATE, OF, SAFEGUARDING, AGAINST, ECONOMIC...   \n",
       "\n",
       "                                                                                                 lower  \\\n",
       "0  [food, security, and, nutrition, in, the, world, the, state, of, safeguarding, against, economic...   \n",
       "\n",
       "                                                                                               no_punc  \\\n",
       "0  [food, security, and, nutrition, in, the, world, the, state, of, safeguarding, against, economic...   \n",
       "\n",
       "                                                                                     stopwords_removed  \n",
       "0  [food, security, nutrition, world, state, safeguarding, economic, slowdowns, downturnsdemocratic...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "df['stopwords_removed'] = df['no_punc'].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://heartbeat.fritz.ai/nlp-chronicles-intro-to-spacy-34949f1bc118#:~:text=Chunking%20is%20the%20process%20of,noun%20of%20a%20given%20chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependency Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    food security and nutrition in the world the state of safeguarding against economic slowdowns an...\n",
       "Name: words_str, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['words_str'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df['words_str'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(type(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1= text.to_string() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ROOT 0 PUNCT [   , security, ...]\n",
      "     0 PUNCT []\n",
      "food compound security NOUN []\n",
      "security nsubj 0 PUNCT [food, and, nutrition, in, state, an]\n",
      "and cc security NOUN []\n",
      "nutrition conj security NOUN []\n",
      "in prep security NOUN [world]\n",
      "the det world NOUN []\n",
      "world pobj in ADP [the]\n",
      "the det state NOUN []\n",
      "state appos security NOUN [the, of]\n",
      "of prep state NOUN [safeguarding]\n",
      "safeguarding pcomp of ADP [against]\n",
      "against prep safeguarding VERB [slowdowns]\n",
      "economic amod slowdowns NOUN []\n",
      "slowdowns pobj against ADP [economic]\n",
      "an appos security NOUN []\n",
      "... punct 0 PUNCT []\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(text1)\n",
    "for token in doc:\n",
    "    print(token.text, token.dep_, token.head.text, token.head.pos_, [child for child in token.children])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising Dependency Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/Manikanta-Munnangi/Natural-Language-Processing-with-spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#displacy.render(doc, style='dep', jupyter=True, options={'distance': 100})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=nlp(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized=[(token.text,token.dep_) for token in doc]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0', 'ROOT'),\n",
       " ('   ', ''),\n",
       " ('food', 'compound'),\n",
       " ('security', 'nsubj'),\n",
       " ('and', 'cc'),\n",
       " ('nutrition', 'conj'),\n",
       " ('in', 'prep'),\n",
       " ('the', 'det'),\n",
       " ('world', 'pobj'),\n",
       " ('the', 'det'),\n",
       " ('state', 'appos'),\n",
       " ('of', 'prep'),\n",
       " ('safeguarding', 'pcomp'),\n",
       " ('against', 'prep'),\n",
       " ('economic', 'amod'),\n",
       " ('slowdowns', 'pobj'),\n",
       " ('an', 'appos'),\n",
       " ('...', 'punct')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print result.\n",
    "tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"b1af5cafe6bd42feb9129bb3c0490a2a-0\" class=\"displacy\" width=\"3025\" height=\"574.5\" direction=\"ltr\" style=\"max-width: none; height: 574.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">0</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PUNCT</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">   </tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">SPACE</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">food</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">security</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">and</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">CCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">nutrition</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">in</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">world</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">state</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1975\">of</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1975\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2150\">safeguarding</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2150\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2325\">against</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2325\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2500\">economic</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2500\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2675\">slowdowns</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2675\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2850\">an...</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2850\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b1af5cafe6bd42feb9129bb3c0490a2a-0-0\" stroke-width=\"2px\" d=\"M70,439.5 C70,352.0 205.0,352.0 205.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b1af5cafe6bd42feb9129bb3c0490a2a-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"></textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M205.0,441.5 L213.0,429.5 197.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b1af5cafe6bd42feb9129bb3c0490a2a-0-1\" stroke-width=\"2px\" d=\"M420,439.5 C420,352.0 555.0,352.0 555.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b1af5cafe6bd42feb9129bb3c0490a2a-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,441.5 L412,429.5 428,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b1af5cafe6bd42feb9129bb3c0490a2a-0-2\" stroke-width=\"2px\" d=\"M70,439.5 C70,177.0 565.0,177.0 565.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b1af5cafe6bd42feb9129bb3c0490a2a-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M565.0,441.5 L573.0,429.5 557.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b1af5cafe6bd42feb9129bb3c0490a2a-0-3\" stroke-width=\"2px\" d=\"M595,439.5 C595,352.0 730.0,352.0 730.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b1af5cafe6bd42feb9129bb3c0490a2a-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M730.0,441.5 L738.0,429.5 722.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b1af5cafe6bd42feb9129bb3c0490a2a-0-4\" stroke-width=\"2px\" d=\"M595,439.5 C595,264.5 910.0,264.5 910.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b1af5cafe6bd42feb9129bb3c0490a2a-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M910.0,441.5 L918.0,429.5 902.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b1af5cafe6bd42feb9129bb3c0490a2a-0-5\" stroke-width=\"2px\" d=\"M595,439.5 C595,177.0 1090.0,177.0 1090.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b1af5cafe6bd42feb9129bb3c0490a2a-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1090.0,441.5 L1098.0,429.5 1082.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b1af5cafe6bd42feb9129bb3c0490a2a-0-6\" stroke-width=\"2px\" d=\"M1295,439.5 C1295,352.0 1430.0,352.0 1430.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b1af5cafe6bd42feb9129bb3c0490a2a-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1295,441.5 L1287,429.5 1303,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b1af5cafe6bd42feb9129bb3c0490a2a-0-7\" stroke-width=\"2px\" d=\"M1120,439.5 C1120,264.5 1435.0,264.5 1435.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b1af5cafe6bd42feb9129bb3c0490a2a-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1435.0,441.5 L1443.0,429.5 1427.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b1af5cafe6bd42feb9129bb3c0490a2a-0-8\" stroke-width=\"2px\" d=\"M1645,439.5 C1645,352.0 1780.0,352.0 1780.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b1af5cafe6bd42feb9129bb3c0490a2a-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1645,441.5 L1637,429.5 1653,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b1af5cafe6bd42feb9129bb3c0490a2a-0-9\" stroke-width=\"2px\" d=\"M595,439.5 C595,89.5 1795.0,89.5 1795.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b1af5cafe6bd42feb9129bb3c0490a2a-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">appos</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1795.0,441.5 L1803.0,429.5 1787.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b1af5cafe6bd42feb9129bb3c0490a2a-0-10\" stroke-width=\"2px\" d=\"M1820,439.5 C1820,352.0 1955.0,352.0 1955.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b1af5cafe6bd42feb9129bb3c0490a2a-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1955.0,441.5 L1963.0,429.5 1947.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b1af5cafe6bd42feb9129bb3c0490a2a-0-11\" stroke-width=\"2px\" d=\"M1995,439.5 C1995,352.0 2130.0,352.0 2130.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b1af5cafe6bd42feb9129bb3c0490a2a-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pcomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2130.0,441.5 L2138.0,429.5 2122.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b1af5cafe6bd42feb9129bb3c0490a2a-0-12\" stroke-width=\"2px\" d=\"M2170,439.5 C2170,352.0 2305.0,352.0 2305.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b1af5cafe6bd42feb9129bb3c0490a2a-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2305.0,441.5 L2313.0,429.5 2297.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b1af5cafe6bd42feb9129bb3c0490a2a-0-13\" stroke-width=\"2px\" d=\"M2520,439.5 C2520,352.0 2655.0,352.0 2655.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b1af5cafe6bd42feb9129bb3c0490a2a-0-13\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2520,441.5 L2512,429.5 2528,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b1af5cafe6bd42feb9129bb3c0490a2a-0-14\" stroke-width=\"2px\" d=\"M2345,439.5 C2345,264.5 2660.0,264.5 2660.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b1af5cafe6bd42feb9129bb3c0490a2a-0-14\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2660.0,441.5 L2668.0,429.5 2652.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b1af5cafe6bd42feb9129bb3c0490a2a-0-15\" stroke-width=\"2px\" d=\"M595,439.5 C595,2.0 2850.0,2.0 2850.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b1af5cafe6bd42feb9129bb3c0490a2a-0-15\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">appos</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2850.0,441.5 L2858.0,429.5 2842.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Rather than see in bare text visualize it as a graph with displacy.\n",
    "from spacy import displacy\n",
    "\n",
    "doc=nlp(text1)\n",
    "# specifying style is dep will render dependency_parser.\n",
    "displacy.render(doc,style='dep',manual=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can access head and multiple childrens.\n",
    "family_tokens=[(token.text,token.head) for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0', 0),\n",
       " ('   ', 0),\n",
       " ('food', security),\n",
       " ('security', 0),\n",
       " ('and', security),\n",
       " ('nutrition', security),\n",
       " ('in', security),\n",
       " ('the', world),\n",
       " ('world', in),\n",
       " ('the', state),\n",
       " ('state', security),\n",
       " ('of', state),\n",
       " ('safeguarding', of),\n",
       " ('against', safeguarding),\n",
       " ('economic', slowdowns),\n",
       " ('slowdowns', against),\n",
       " ('an', security),\n",
       " ('...', 0)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "family_tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part Of Speech Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through doc and return tokens with .text\n",
    "tokenized=[(token.text,token.pos_,token.tag_) for token in doc]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0', 'PUNCT', 'NFP'),\n",
       " ('   ', 'SPACE', '_SP'),\n",
       " ('food', 'NOUN', 'NN'),\n",
       " ('security', 'NOUN', 'NN'),\n",
       " ('and', 'CCONJ', 'CC'),\n",
       " ('nutrition', 'NOUN', 'NN'),\n",
       " ('in', 'ADP', 'IN'),\n",
       " ('the', 'DET', 'DT'),\n",
       " ('world', 'NOUN', 'NN'),\n",
       " ('the', 'DET', 'DT'),\n",
       " ('state', 'NOUN', 'NN'),\n",
       " ('of', 'ADP', 'IN'),\n",
       " ('safeguarding', 'VERB', 'VBG'),\n",
       " ('against', 'ADP', 'IN'),\n",
       " ('economic', 'ADJ', 'JJ'),\n",
       " ('slowdowns', 'NOUN', 'NNS'),\n",
       " ('an', 'DET', 'DT'),\n",
       " ('...', 'PUNCT', '.')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# print result.\n",
    "tokenized\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 PUNCT\n",
      "    SPACE\n",
      "food NOUN\n",
      "security NOUN\n",
      "and CCONJ\n",
      "nutrition NOUN\n",
      "in ADP\n",
      "the DET\n",
      "world NOUN\n",
      "the DET\n",
      "state NOUN\n",
      "of ADP\n",
      "safeguarding VERB\n",
      "against ADP\n",
      "economic ADJ\n",
      "slowdowns NOUN\n",
      "an DET\n",
      "... PUNCT\n"
     ]
    }
   ],
   "source": [
    "for word in doc:\n",
    "    print(word.text, word.pos_)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 PUNCT NFP\n",
      "    SPACE _SP\n",
      "food NOUN NN\n",
      "security NOUN NN\n",
      "and CCONJ CC\n",
      "nutrition NOUN NN\n",
      "in ADP IN\n",
      "the DET DT\n",
      "world NOUN NN\n",
      "the DET DT\n",
      "state NOUN NN\n",
      "of ADP IN\n",
      "safeguarding VERB VBG\n",
      "against ADP IN\n",
      "economic ADJ JJ\n",
      "slowdowns NOUN NNS\n",
      "an DET DT\n",
      "... PUNCT .\n"
     ]
    }
   ],
   "source": [
    "for word in doc:\n",
    "    print(word.text, word.pos_, word.tag_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 PUNCT NFP ROOT\n",
      "    SPACE _SP \n",
      "food NOUN NN compound\n",
      "security NOUN NN nsubj\n",
      "and CCONJ CC cc\n",
      "nutrition NOUN NN conj\n",
      "in ADP IN prep\n",
      "the DET DT det\n",
      "world NOUN NN pobj\n",
      "the DET DT det\n",
      "state NOUN NN appos\n",
      "of ADP IN prep\n",
      "safeguarding VERB VBG pcomp\n",
      "against ADP IN prep\n",
      "economic ADJ JJ amod\n",
      "slowdowns NOUN NNS pobj\n",
      "an DET DT appos\n",
      "... PUNCT . punct\n"
     ]
    }
   ],
   "source": [
    "for word in doc:\n",
    "    print(word.text, word.pos_, word.tag_, word.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['food', 'security', 'nutrition', 'world', 'state', 'slowdowns']\n"
     ]
    }
   ],
   "source": [
    "nouns = [token for token, pos in pos_tag(word_tokenize(text1)) if (pos.startswith('NN') or pos.startswith('NS') or pos.startswith('NNP')or pos.startswith('NPS'))]\n",
    "print(nouns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 PUNCT NFP d False False\n",
      "    SPACE _SP     False False\n",
      "food NOUN NN xxxx True False\n",
      "security NOUN NN xxxx True False\n",
      "and CCONJ CC xxx True True\n",
      "nutrition NOUN NN xxxx True False\n",
      "in ADP IN xx True True\n",
      "the DET DT xxx True True\n",
      "world NOUN NN xxxx True False\n",
      "the DET DT xxx True True\n",
      "state NOUN NN xxxx True False\n",
      "of ADP IN xx True True\n",
      "safeguarding VERB VBG xxxx True False\n",
      "against ADP IN xxxx True True\n",
      "economic ADJ JJ xxxx True False\n",
      "slowdowns NOUN NNS xxxx True False\n",
      "an DET DT xx True True\n",
      "... PUNCT . ... False False\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.tag_, token.shape_, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/a-practitioners-guide-to-natural-language-processing-part-i-processing-understanding-text-9f4abfd13e72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>POS tag</th>\n",
       "      <th>Tag type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NFP</td>\n",
       "      <td>PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>_SP</td>\n",
       "      <td>SPACE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>food</td>\n",
       "      <td>NN</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>security</td>\n",
       "      <td>NN</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>and</td>\n",
       "      <td>CC</td>\n",
       "      <td>CCONJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>nutrition</td>\n",
       "      <td>NN</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>in</td>\n",
       "      <td>IN</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>world</td>\n",
       "      <td>NN</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>state</td>\n",
       "      <td>NN</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>safeguarding</td>\n",
       "      <td>VBG</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>against</td>\n",
       "      <td>IN</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>economic</td>\n",
       "      <td>JJ</td>\n",
       "      <td>ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>slowdowns</td>\n",
       "      <td>NNS</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>an</td>\n",
       "      <td>DT</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Word POS tag Tag type\n",
       "0              0     NFP    PUNCT\n",
       "1                    _SP    SPACE\n",
       "2           food      NN     NOUN\n",
       "3       security      NN     NOUN\n",
       "4            and      CC    CCONJ\n",
       "5      nutrition      NN     NOUN\n",
       "6             in      IN      ADP\n",
       "7            the      DT      DET\n",
       "8          world      NN     NOUN\n",
       "9            the      DT      DET\n",
       "10         state      NN     NOUN\n",
       "11            of      IN      ADP\n",
       "12  safeguarding     VBG     VERB\n",
       "13       against      IN      ADP\n",
       "14      economic      JJ      ADJ\n",
       "15     slowdowns     NNS     NOUN\n",
       "16            an      DT      DET\n",
       "17           ...       .    PUNCT"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# POS tagging with Spacy \n",
    "spacy_pos_tagged = [(word, word.tag_, word.pos_) for word in doc]\n",
    "pd.DataFrame(spacy_pos_tagged, columns=['Word', 'POS tag', 'Tag type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sentence' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-d0c1d49d0e30>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# POS tagging with nltk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mnltk_pos_tagged\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos_tag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnltk_pos_tagged\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Word'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'POS tag'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sentence' is not defined"
     ]
    }
   ],
   "source": [
    "# POS tagging with nltk\n",
    "\n",
    "nltk_pos_tagged = nltk.pos_tag(sentence.split())\n",
    "pd.DataFrame(nltk_pos_tagged, columns=['Word', 'POS tag'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part of speech tagging\n",
    "In your childhood, you may have heard the term Part of Speech (POS). It can really take good amount of time to get the hang of what adjectives and adverbs actually are. What exactly is the difference? Think about building a system where we can encode all this knowledge. It may look very easy, but for many decades, coding this knowledge into a machine learning model was a very hard NLP problem. POS tagging algorithms can predict the POS of the given word with a higher degree of precision. You can get the POS of individual words as a tuple\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://datascience.foundation/sciencewhitepaper/natural-language-processing-nlp-simplified-a-step-by-step-guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('0', 'CD'), ('food', 'NN'), ('security', 'NN'), ('and', 'CC'), ('nutrition', 'NN'), ('in', 'IN'), ('the', 'DT'), ('world', 'NN'), ('the', 'DT'), ('state', 'NN'), ('of', 'IN'), ('safeguarding', 'VBG'), ('against', 'IN'), ('economic', 'JJ'), ('slowdowns', 'NNS'), ('an', 'DT'), ('...', ':')]\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize, pos_tag\n",
    "print(pos_tag(word_tokenize(text1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['food', 'security', 'nutrition', 'world', 'state']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = nltk.word_tokenize(text1)\n",
    "tags = nltk.pos_tag(tokens)\n",
    "nouns = [word for word,pos in tags if (pos == 'NNP' or pos == 'NN' or pos == 'NS' or pos == 'NPS')]\n",
    "nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         food\n",
       "1     security\n",
       "2    nutrition\n",
       "3        world\n",
       "4        state\n",
       "dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feedback = pd.Series(nouns) \n",
    "\n",
    "feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to know the details of the POS, here is the way. Note we might need to download the tagset. Below example shows NN is noun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package tagsets to\n",
      "[nltk_data]     C:\\Users\\mwamb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package tagsets is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('tagsets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN: noun, common, singular or mass\n",
      "    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
      "    investment slide humour falloff slick wind hyena override subhumanity\n",
      "    machinist ...\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset('NN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT: determiner\n",
      "    all an another any both del each either every half la many much nary\n",
      "    neither no some such that the them these this those\n",
      "IN: preposition or conjunction, subordinating\n",
      "    astride among uppon whether out inside pro despite on by throughout\n",
      "    below within for towards near behind atop around if like until below\n",
      "    next into if beside ...\n",
      "VBZ: verb, present tense, 3rd person singular\n",
      "    bases reconstructs marks mixes displeases seals carps weaves snatches\n",
      "    slumps stretches authorizes smolders pictures emerges stockpiles\n",
      "    seduces fizzes uses bolsters slaps speaks pleads ...\n",
      "NNP: noun, proper, singular\n",
      "    Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos\n",
      "    Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA\n",
      "    Shannon A.K.C. Meltex Liverpool ...\n",
      "PRP$: pronoun, possessive\n",
      "    her his mine my our ours their thy your\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset('DT')\n",
    "nltk.help.upenn_tagset('IN')\n",
    "nltk.help.upenn_tagset('VBZ')\n",
    "nltk.help.upenn_tagset('NNP')\n",
    "nltk.help.upenn_tagset('PRP$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0    food security and nutrition in the world the state of safeguarding against economic slowdowns an...'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('the', 'DT')\n",
      "('the', 'DT')\n",
      "('an', 'DT')\n"
     ]
    }
   ],
   "source": [
    "text2= nltk.sent_tokenize(text1)\n",
    "data=[]\n",
    "for sent in text2:\n",
    "    data = data + nltk.pos_tag(nltk.word_tokenize(sent))\n",
    "    \n",
    "    \n",
    "for word in data:\n",
    "    if 'DT' in word[1]:\n",
    "        print(word)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_, ent.start_char, ent.end_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunking\n",
    "\n",
    "\n",
    "Chunking is the process of extracting noun phrases from the text.  \n",
    "spaCy can identify noun phrases (or noun chunks), as well. You can think of noun chunks as a noun plus the words describing the    noun. Its also possible to identify and extract the base-noun of a given chunk.   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://heartbeat.fritz.ai/nlp-chronicles-intro-to-spacy-34949f1bc118#:~:text=Chunking%20is%20the%20process%20of,noun%20of%20a%20given%20chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "food security security nsubj 0\n",
      "nutrition nutrition conj security\n",
      "the world world pobj in\n",
      "the state state appos security\n",
      "economic slowdowns slowdowns pobj against\n"
     ]
    }
   ],
   "source": [
    "for chunk in doc.noun_chunks:\n",
    "    print(chunk.text, chunk.root.text, chunk.root.dep_, chunk.root.head.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/40167612/how-to-keep-only-the-noun-words-in-a-wordlist-python-nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Named Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mwamb\\Anaconda3\\lib\\site-packages\\spacy\\displacy\\__init__.py:189: UserWarning: [W006] No entities to visualize found in Doc object. If this is surprising to you, make sure the Doc was processed using a model that supports named entity recognition, and check the `doc.ents` property manually if necessary.\n",
      "  warnings.warn(Warnings.W006)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">0    food security and nutrition in the world the state of safeguarding against economic slowdowns an...</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "import en_core_web_sm\n",
    "sp = en_core_web_sm.load()\n",
    "    \n",
    "#sp = spacy.load('en_core_web_sm')\n",
    "sen = sp(text1)\n",
    "displacy.render(sen, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0    food security and nutrition in the world the state of safeguarding against economic slowdowns an...'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">0    food security and nutrition in the world the state of safeguarding against economic slowdowns an...</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filter = {'ents': ['ORG']}\n",
    "displacy.render(sen, style='ent', jupyter=True, options=filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#displacy.serve(sen, style='ent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming vs Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>words</th>\n",
       "      <th>no_contract</th>\n",
       "      <th>words_str</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>lower</th>\n",
       "      <th>no_punc</th>\n",
       "      <th>stopwords_removed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>WFP</td>\n",
       "      <td>FOOD SECURITY \\n AND NUTRITION \\nIN THE WORLD\\nTHE STATE OF \\nSAFEGUARDING AGAINST \\nECONOMIC SL...</td>\n",
       "      <td>[FOOD, SECURITY, AND, NUTRITION, IN, THE, WORLD, THE, STATE, OF, SAFEGUARDING, AGAINST, ECONOMIC...</td>\n",
       "      <td>FOOD SECURITY AND NUTRITION IN THE WORLD THE STATE OF SAFEGUARDING AGAINST ECONOMIC SLOWDOWNS AN...</td>\n",
       "      <td>[FOOD, SECURITY, AND, NUTRITION, IN, THE, WORLD, THE, STATE, OF, SAFEGUARDING, AGAINST, ECONOMIC...</td>\n",
       "      <td>[food, security, and, nutrition, in, the, world, the, state, of, safeguarding, against, economic...</td>\n",
       "      <td>[food, security, and, nutrition, in, the, world, the, state, of, safeguarding, against, economic...</td>\n",
       "      <td>[food, security, nutrition, world, state, safeguarding, economic, slowdowns, downturnsdemocratic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cluster  \\\n",
       "0     WFP   \n",
       "\n",
       "                                                                                                 words  \\\n",
       "0  FOOD SECURITY \\n AND NUTRITION \\nIN THE WORLD\\nTHE STATE OF \\nSAFEGUARDING AGAINST \\nECONOMIC SL...   \n",
       "\n",
       "                                                                                           no_contract  \\\n",
       "0  [FOOD, SECURITY, AND, NUTRITION, IN, THE, WORLD, THE, STATE, OF, SAFEGUARDING, AGAINST, ECONOMIC...   \n",
       "\n",
       "                                                                                             words_str  \\\n",
       "0  FOOD SECURITY AND NUTRITION IN THE WORLD THE STATE OF SAFEGUARDING AGAINST ECONOMIC SLOWDOWNS AN...   \n",
       "\n",
       "                                                                                             tokenized  \\\n",
       "0  [FOOD, SECURITY, AND, NUTRITION, IN, THE, WORLD, THE, STATE, OF, SAFEGUARDING, AGAINST, ECONOMIC...   \n",
       "\n",
       "                                                                                                 lower  \\\n",
       "0  [food, security, and, nutrition, in, the, world, the, state, of, safeguarding, against, economic...   \n",
       "\n",
       "                                                                                               no_punc  \\\n",
       "0  [food, security, and, nutrition, in, the, world, the, state, of, safeguarding, against, economic...   \n",
       "\n",
       "                                                                                     stopwords_removed  \n",
       "0  [food, security, nutrition, world, state, safeguarding, economic, slowdowns, downturnsdemocratic...  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>words</th>\n",
       "      <th>no_contract</th>\n",
       "      <th>words_str</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>lower</th>\n",
       "      <th>no_punc</th>\n",
       "      <th>stopwords_removed</th>\n",
       "      <th>pos_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>WFP</td>\n",
       "      <td>FOOD SECURITY \\n AND NUTRITION \\nIN THE WORLD\\nTHE STATE OF \\nSAFEGUARDING AGAINST \\nECONOMIC SL...</td>\n",
       "      <td>[FOOD, SECURITY, AND, NUTRITION, IN, THE, WORLD, THE, STATE, OF, SAFEGUARDING, AGAINST, ECONOMIC...</td>\n",
       "      <td>FOOD SECURITY AND NUTRITION IN THE WORLD THE STATE OF SAFEGUARDING AGAINST ECONOMIC SLOWDOWNS AN...</td>\n",
       "      <td>[FOOD, SECURITY, AND, NUTRITION, IN, THE, WORLD, THE, STATE, OF, SAFEGUARDING, AGAINST, ECONOMIC...</td>\n",
       "      <td>[food, security, and, nutrition, in, the, world, the, state, of, safeguarding, against, economic...</td>\n",
       "      <td>[food, security, and, nutrition, in, the, world, the, state, of, safeguarding, against, economic...</td>\n",
       "      <td>[food, security, nutrition, world, state, safeguarding, economic, slowdowns, downturnsdemocratic...</td>\n",
       "      <td>[(food, NN), (security, NN), (nutrition, NN), (world, NN), (state, NN), (safeguarding, VBG), (ec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cluster  \\\n",
       "0     WFP   \n",
       "\n",
       "                                                                                                 words  \\\n",
       "0  FOOD SECURITY \\n AND NUTRITION \\nIN THE WORLD\\nTHE STATE OF \\nSAFEGUARDING AGAINST \\nECONOMIC SL...   \n",
       "\n",
       "                                                                                           no_contract  \\\n",
       "0  [FOOD, SECURITY, AND, NUTRITION, IN, THE, WORLD, THE, STATE, OF, SAFEGUARDING, AGAINST, ECONOMIC...   \n",
       "\n",
       "                                                                                             words_str  \\\n",
       "0  FOOD SECURITY AND NUTRITION IN THE WORLD THE STATE OF SAFEGUARDING AGAINST ECONOMIC SLOWDOWNS AN...   \n",
       "\n",
       "                                                                                             tokenized  \\\n",
       "0  [FOOD, SECURITY, AND, NUTRITION, IN, THE, WORLD, THE, STATE, OF, SAFEGUARDING, AGAINST, ECONOMIC...   \n",
       "\n",
       "                                                                                                 lower  \\\n",
       "0  [food, security, and, nutrition, in, the, world, the, state, of, safeguarding, against, economic...   \n",
       "\n",
       "                                                                                               no_punc  \\\n",
       "0  [food, security, and, nutrition, in, the, world, the, state, of, safeguarding, against, economic...   \n",
       "\n",
       "                                                                                     stopwords_removed  \\\n",
       "0  [food, security, nutrition, world, state, safeguarding, economic, slowdowns, downturnsdemocratic...   \n",
       "\n",
       "                                                                                              pos_tags  \n",
       "0  [(food, NN), (security, NN), (nutrition, NN), (world, NN), (state, NN), (safeguarding, VBG), (ec...  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pos_tags'] = df['stopwords_removed'].apply(nltk.tag.pos_tag)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>words</th>\n",
       "      <th>no_contract</th>\n",
       "      <th>words_str</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>lower</th>\n",
       "      <th>no_punc</th>\n",
       "      <th>stopwords_removed</th>\n",
       "      <th>pos_tags</th>\n",
       "      <th>wordnet_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>WFP</td>\n",
       "      <td>FOOD SECURITY \\n AND NUTRITION \\nIN THE WORLD\\nTHE STATE OF \\nSAFEGUARDING AGAINST \\nECONOMIC SL...</td>\n",
       "      <td>[FOOD, SECURITY, AND, NUTRITION, IN, THE, WORLD, THE, STATE, OF, SAFEGUARDING, AGAINST, ECONOMIC...</td>\n",
       "      <td>FOOD SECURITY AND NUTRITION IN THE WORLD THE STATE OF SAFEGUARDING AGAINST ECONOMIC SLOWDOWNS AN...</td>\n",
       "      <td>[FOOD, SECURITY, AND, NUTRITION, IN, THE, WORLD, THE, STATE, OF, SAFEGUARDING, AGAINST, ECONOMIC...</td>\n",
       "      <td>[food, security, and, nutrition, in, the, world, the, state, of, safeguarding, against, economic...</td>\n",
       "      <td>[food, security, and, nutrition, in, the, world, the, state, of, safeguarding, against, economic...</td>\n",
       "      <td>[food, security, nutrition, world, state, safeguarding, economic, slowdowns, downturnsdemocratic...</td>\n",
       "      <td>[(food, NN), (security, NN), (nutrition, NN), (world, NN), (state, NN), (safeguarding, VBG), (ec...</td>\n",
       "      <td>[(food, n), (security, n), (nutrition, n), (world, n), (state, n), (safeguarding, v), (economic,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cluster  \\\n",
       "0     WFP   \n",
       "\n",
       "                                                                                                 words  \\\n",
       "0  FOOD SECURITY \\n AND NUTRITION \\nIN THE WORLD\\nTHE STATE OF \\nSAFEGUARDING AGAINST \\nECONOMIC SL...   \n",
       "\n",
       "                                                                                           no_contract  \\\n",
       "0  [FOOD, SECURITY, AND, NUTRITION, IN, THE, WORLD, THE, STATE, OF, SAFEGUARDING, AGAINST, ECONOMIC...   \n",
       "\n",
       "                                                                                             words_str  \\\n",
       "0  FOOD SECURITY AND NUTRITION IN THE WORLD THE STATE OF SAFEGUARDING AGAINST ECONOMIC SLOWDOWNS AN...   \n",
       "\n",
       "                                                                                             tokenized  \\\n",
       "0  [FOOD, SECURITY, AND, NUTRITION, IN, THE, WORLD, THE, STATE, OF, SAFEGUARDING, AGAINST, ECONOMIC...   \n",
       "\n",
       "                                                                                                 lower  \\\n",
       "0  [food, security, and, nutrition, in, the, world, the, state, of, safeguarding, against, economic...   \n",
       "\n",
       "                                                                                               no_punc  \\\n",
       "0  [food, security, and, nutrition, in, the, world, the, state, of, safeguarding, against, economic...   \n",
       "\n",
       "                                                                                     stopwords_removed  \\\n",
       "0  [food, security, nutrition, world, state, safeguarding, economic, slowdowns, downturnsdemocratic...   \n",
       "\n",
       "                                                                                              pos_tags  \\\n",
       "0  [(food, NN), (security, NN), (nutrition, NN), (world, NN), (state, NN), (safeguarding, VBG), (ec...   \n",
       "\n",
       "                                                                                           wordnet_pos  \n",
       "0  [(food, n), (security, n), (nutrition, n), (world, n), (state, n), (safeguarding, v), (economic,...  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "df['wordnet_pos'] = df['pos_tags'].apply(lambda x: [(word, get_wordnet_pos(pos_tag)) for (word, pos_tag) in x])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>words</th>\n",
       "      <th>no_contract</th>\n",
       "      <th>words_str</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>lower</th>\n",
       "      <th>no_punc</th>\n",
       "      <th>stopwords_removed</th>\n",
       "      <th>pos_tags</th>\n",
       "      <th>wordnet_pos</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>WFP</td>\n",
       "      <td>FOOD SECURITY \\n AND NUTRITION \\nIN THE WORLD\\nTHE STATE OF \\nSAFEGUARDING AGAINST \\nECONOMIC SL...</td>\n",
       "      <td>[FOOD, SECURITY, AND, NUTRITION, IN, THE, WORLD, THE, STATE, OF, SAFEGUARDING, AGAINST, ECONOMIC...</td>\n",
       "      <td>FOOD SECURITY AND NUTRITION IN THE WORLD THE STATE OF SAFEGUARDING AGAINST ECONOMIC SLOWDOWNS AN...</td>\n",
       "      <td>[FOOD, SECURITY, AND, NUTRITION, IN, THE, WORLD, THE, STATE, OF, SAFEGUARDING, AGAINST, ECONOMIC...</td>\n",
       "      <td>[food, security, and, nutrition, in, the, world, the, state, of, safeguarding, against, economic...</td>\n",
       "      <td>[food, security, and, nutrition, in, the, world, the, state, of, safeguarding, against, economic...</td>\n",
       "      <td>[food, security, nutrition, world, state, safeguarding, economic, slowdowns, downturnsdemocratic...</td>\n",
       "      <td>[(food, NN), (security, NN), (nutrition, NN), (world, NN), (state, NN), (safeguarding, VBG), (ec...</td>\n",
       "      <td>[(food, n), (security, n), (nutrition, n), (world, n), (state, n), (safeguarding, v), (economic,...</td>\n",
       "      <td>[food, security, nutrition, world, state, safeguard, economic, slowdown, downturnsdemocratic, re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cluster  \\\n",
       "0     WFP   \n",
       "\n",
       "                                                                                                 words  \\\n",
       "0  FOOD SECURITY \\n AND NUTRITION \\nIN THE WORLD\\nTHE STATE OF \\nSAFEGUARDING AGAINST \\nECONOMIC SL...   \n",
       "\n",
       "                                                                                           no_contract  \\\n",
       "0  [FOOD, SECURITY, AND, NUTRITION, IN, THE, WORLD, THE, STATE, OF, SAFEGUARDING, AGAINST, ECONOMIC...   \n",
       "\n",
       "                                                                                             words_str  \\\n",
       "0  FOOD SECURITY AND NUTRITION IN THE WORLD THE STATE OF SAFEGUARDING AGAINST ECONOMIC SLOWDOWNS AN...   \n",
       "\n",
       "                                                                                             tokenized  \\\n",
       "0  [FOOD, SECURITY, AND, NUTRITION, IN, THE, WORLD, THE, STATE, OF, SAFEGUARDING, AGAINST, ECONOMIC...   \n",
       "\n",
       "                                                                                                 lower  \\\n",
       "0  [food, security, and, nutrition, in, the, world, the, state, of, safeguarding, against, economic...   \n",
       "\n",
       "                                                                                               no_punc  \\\n",
       "0  [food, security, and, nutrition, in, the, world, the, state, of, safeguarding, against, economic...   \n",
       "\n",
       "                                                                                     stopwords_removed  \\\n",
       "0  [food, security, nutrition, world, state, safeguarding, economic, slowdowns, downturnsdemocratic...   \n",
       "\n",
       "                                                                                              pos_tags  \\\n",
       "0  [(food, NN), (security, NN), (nutrition, NN), (world, NN), (state, NN), (safeguarding, VBG), (ec...   \n",
       "\n",
       "                                                                                           wordnet_pos  \\\n",
       "0  [(food, n), (security, n), (nutrition, n), (world, n), (state, n), (safeguarding, v), (economic,...   \n",
       "\n",
       "                                                                                            lemmatized  \n",
       "0  [food, security, nutrition, world, state, safeguard, economic, slowdown, downturnsdemocratic, re...  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wnl = WordNetLemmatizer()\n",
    "df['lemmatized'] = df['wordnet_pos'].apply(lambda x: [wnl.lemmatize(word, tag) for word, tag in x])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/summarization-of-covid-research-papers-using-bart-model-5b109a6669a6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither PyTorch nor TensorFlow >= 2.0 have been found.Models won't be available and only tokenizers, configurationand file/data utilities can be used.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "At least one of TensorFlow 2.0 or PyTorch should be installed. To install TensorFlow 2.0, read the instructions at https://www.tensorflow.org/install/ To install PyTorch, read the instructions at https://pytorch.org/.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-b922f1da2134>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msummarizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"summarization\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\transformers\\pipelines.py\u001b[0m in \u001b[0;36mpipeline\u001b[1;34m(task, model, config, tokenizer, framework, **kwargs)\u001b[0m\n\u001b[0;32m   2725\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_default_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtargeted_task\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframework\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2726\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2727\u001b[1;33m     \u001b[0mframework\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mframework\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mget_framework\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2729\u001b[0m     \u001b[0mtask_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtargeted_task\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"impl\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargeted_task\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mframework\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\transformers\\pipelines.py\u001b[0m in \u001b[0;36mget_framework\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_tf_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_torch_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m         raise RuntimeError(\n\u001b[1;32m---> 99\u001b[1;33m             \u001b[1;34m\"At least one of TensorFlow 2.0 or PyTorch should be installed. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m             \u001b[1;34m\"To install TensorFlow 2.0, read the instructions at https://www.tensorflow.org/install/ \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m             \u001b[1;34m\"To install PyTorch, read the instructions at https://pytorch.org/.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: At least one of TensorFlow 2.0 or PyTorch should be installed. To install TensorFlow 2.0, read the instructions at https://www.tensorflow.org/install/ To install PyTorch, read the instructions at https://pytorch.org/."
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "summarizer = pipeline(\"summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.to_pickle(\"C:/Users/mwamb/OneDrive/Desktop/tenthdimensionanalytics/WFP/processed_data/wfpdata_clean\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
